{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZE5rkL3gB2f",
        "outputId": "a253a087-3556-4550-da66-af66372db326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "\n",
        "model_name = \"DeepPavlov/rubert-base-cased\"\n",
        "model = transformers.AutoModel.from_pretrained(model_name)\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"test50.csv\")"
      ],
      "metadata": {
        "id": "EuluIKEVgZut"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "Embedding = []\n",
        "Target = []\n",
        "for i in tqdm(range(len(data))):\n",
        "  sentence = data[\"Отзывы\"][i]\n",
        "  tokenized = tokenizer(sentence, return_tensors=\"pt\")\n",
        "  embeddings = model(**tokenized, output_hidden_states=True).last_hidden_state\n",
        "  Embedding.append(embeddings[0][1])\n",
        "  del embeddings\n",
        "  if data[\"разметка\"][i][0] == \"+\":\n",
        "    Target.append(1)\n",
        "  elif data[\"разметка\"][i][0] == \"-\":\n",
        "    Target.append(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il07FbIegcLD",
        "outputId": "7f50a004-859d-4818-a381-7f71aa063a27"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:09<00:00,  5.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, target):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.features[idx]\n",
        "        y = self.target[idx]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "test_dataset =CustomDataset(Embedding, Target)"
      ],
      "metadata": {
        "id": "9dRjSP1EgqSG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision.models.vision_transformer import MLPBlock\n",
        "\n",
        "### Training function\n",
        "def train_epoch(model, device, dataloader, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    accuracy=0\n",
        "    for embed, y in dataloader:\n",
        "        embed = embed.detach().to(device)\n",
        "        y = y.to(device)\n",
        "        # Embedded data\n",
        "        pred = model(embed)\n",
        "        # Accuracy\n",
        "        ps = torch.exp(pred)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == y.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "        # Loss function\n",
        "        loss = loss_fn(pred, y)\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss.append(loss.detach().cpu().numpy())\n",
        "    return np.mean(train_loss), accuracy/len(dataloader)\n",
        "\n",
        "### Testing function\n",
        "def test_epoch(model, device, dataloader, loss_fn):\n",
        "    model.eval()\n",
        "    with torch.no_grad(): # No need to track the gradients\n",
        "        # Define the lists to store the outputs for each batch\n",
        "        conc_out = []\n",
        "        conc_label = []\n",
        "        accuracy=0\n",
        "        for embed, y in dataloader:\n",
        "            # Move tensor to the proper device\n",
        "            embed = embed.to(device)\n",
        "            y = y.to(device)\n",
        "            # Decode data\n",
        "            pred = model(embed)\n",
        "            # Accuracy\n",
        "            ps = torch.exp(pred)\n",
        "            top_p, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == y.view(*top_class.shape)\n",
        "            accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "            conc_out.append(pred.cpu())\n",
        "            conc_label.append(y.cpu())\n",
        "        # Create a single tensor with all the values in the lists\n",
        "        conc_out = torch.cat(conc_out)\n",
        "        conc_label = torch.cat(conc_label)\n",
        "        # Evaluate global loss\n",
        "        val_loss = loss_fn(conc_out, conc_label)\n",
        "    return val_loss.data, accuracy/len(dataloader)"
      ],
      "metadata": {
        "id": "xJWXJVrbgqwZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit\n",
        "!pip install qiskit_machine_learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfpiGSRLhtd1",
        "outputId": "f0c49690-64f2-44d9-f42e-1ffd6b514f9d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-1.2.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Collecting dill>=0.3 (from qiskit)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.2)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Downloading qiskit-1.2.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.3.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: symengine, rustworkx, pbr, dill, stevedore, qiskit\n",
            "Successfully installed dill-0.3.9 pbr-6.1.0 qiskit-1.2.4 rustworkx-0.15.1 stevedore-5.3.0 symengine-0.13.0\n",
            "Collecting qiskit_machine_learning\n",
            "  Downloading qiskit_machine_learning-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: qiskit>=1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.2.4)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.5.2)\n",
            "Collecting fastdtw (from qiskit_machine_learning)\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (75.1.0)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (0.3.9)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (0.15.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (0.13.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit_machine_learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit_machine_learning) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=1.0->qiskit_machine_learning) (1.16.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit>=1.0->qiskit_machine_learning) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=1.0->qiskit_machine_learning) (1.3.0)\n",
            "Downloading qiskit_machine_learning-0.8.0-py3-none-any.whl (237 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fastdtw\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp310-cp310-linux_x86_64.whl size=512550 sha256=e13ef9d65622acbc9bb47f0a0b303d85500e57be8005f8fb4244cb90e53a6d93\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/c8/f7/c25448dab74c3acf4848bc25d513c736bb93910277e1528ef4\n",
            "Successfully built fastdtw\n",
            "Installing collected packages: fastdtw, qiskit_machine_learning\n",
            "Successfully installed fastdtw-0.3.4 qiskit_machine_learning-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import Tensor\n",
        "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
        "from torch.optim import LBFGS\n",
        "\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit import Parameter\n",
        "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
        "from qiskit_machine_learning.utils import algorithm_globals\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "import torch\n",
        "from torch import cat, no_grad, manual_seed\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "from torch.nn import (\n",
        "    Module,\n",
        "    Conv2d,\n",
        "    Linear,\n",
        "    Dropout2d,\n",
        "    NLLLoss,\n",
        "    MaxPool2d,\n",
        "    Flatten,\n",
        "    Sequential,\n",
        "    ReLU,\n",
        ")\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "eCPFsU_og6vO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_qnn(qbit = 2, reps=1):\n",
        "    feature_map = ZZFeatureMap(qbit)\n",
        "    ansatz = RealAmplitudes(qbit, reps=reps)\n",
        "    qc = QuantumCircuit(qbit)\n",
        "    qc.compose(feature_map, inplace=True)\n",
        "    qc.compose(ansatz, inplace=True)\n",
        "\n",
        "    qnn = EstimatorQNN(\n",
        "        circuit=qc,\n",
        "        input_params=feature_map.parameters,\n",
        "        weight_params=ansatz.parameters,\n",
        "        input_gradients=True,\n",
        "    )\n",
        "    return qnn"
      ],
      "metadata": {
        "id": "fpaAhDyyg_Vk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Net(Module):\n",
        "    def __init__(self, qbit = 2, reps=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1 = Linear(768, 400)\n",
        "        self.fc2 = Linear(400, 100)\n",
        "        self.fc3 = Linear(100,qbit)  # 2-dimensional input to QNN\n",
        "        self.qnn = TorchConnector(create_qnn(qbit, reps))  # Apply torch connector, weights chosen\n",
        "        # uniformly at random from interval [-1,1].\n",
        "        self.fc4 = Linear(1, 1)  # 1-dimensional output from QNN\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = self.qnn(x)  # apply QNN\n",
        "        x = self.fc4(x)\n",
        "        return cat((x, 1 - x), -1)"
      ],
      "metadata": {
        "id": "8N6EosowhCju"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Net(qbit = 3, reps=2)\n",
        "\n",
        "model.load_state_dict(torch.load(\"q_model_3qubits.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Ts0wx7hH43",
        "outputId": "86e86a17-41f7-42a6-e96c-a4ade9a5bd8d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-8d525dc1955b>:8: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  qnn = EstimatorQNN(\n",
            "<ipython-input-13-8d525dc1955b>:8: UserWarning: No number of qubits was not specified (None) and was retrieved from `circuit` (3). If `circuit` is transpiled, this may cause unstable behaviour.\n",
            "  qnn = EstimatorQNN(\n",
            "<ipython-input-15-37da96de0134>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"q_model_3qubits.pt\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset =CustomDataset(Embedding, Target)\n",
        "batch_size = 50\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "loss_fn = nn.NLLLoss()\n",
        "test_loss, test_acc = test_epoch(model, device, test_loader, loss_fn)\n",
        "print('Accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJAQfcHVhNJM",
        "outputId": "e05dde60-e717-4c79-95ab-8de844007074"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: tensor(0.8200)\n"
          ]
        }
      ]
    }
  ]
}